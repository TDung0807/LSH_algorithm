{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requiment 1"
      ],
      "metadata": {
        "id": "6h3u_GQOVaIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "uPqyY43fVi3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lL4pxe1GVlqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "4jfP_eUIlgOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.readlines()\n",
        "    df = pd.DataFrame(text, columns=[\"Text\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "UVj_xc0Ele3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSH"
      ],
      "metadata": {
        "id": "3sNgM1e1lVph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shingling"
      ],
      "metadata": {
        "id": "yr_u3ZVblYrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "class InMemoryMinHashLSH:\n",
        "    def read_file(filename):\n",
        "      with open(filename, 'r') as file:\n",
        "          text = file.readlines()\n",
        "      df = pd.DataFrame(text, columns=[\"Text\"])\n",
        "      return df\n",
        "    def __init__(self, documents):\n",
        "      ##Init self data\n",
        "      data = read_file(\"/content/WebOfScience-5736.txt\")\n",
        "      self.documents = data\n",
        "      self.shingled_self = self.shingling()\n",
        "      self.minhashing_self = None\n",
        "      self.lsh_self = None\n",
        "\n",
        "      ## Init Query data\n",
        "      self.documents = documents\n",
        "      self.shingled_query = self.shingling()\n",
        "      self.minhashing_query = None\n",
        "      self.lsh_query = None\n",
        "\n",
        "      self.boolean_vectors_self, self.boolean_vectors_query = self.convert_to_boolean_vectors()\n",
        "\n",
        "\n",
        "    def convert_to_boolean_vectors(self):\n",
        "      bool_vectors_query = []\n",
        "      bool_vectors_self = []\n",
        "      # Create a set to store all unique shingles from both self and query shingled data\n",
        "      shingles_set = set()\n",
        "      shingles_set.update(self.shingled_self)\n",
        "      shingles_set.update(self.shingled_query)\n",
        "      for eles in shingles_set:\n",
        "        if eles in self.shingled_self:\n",
        "          bool_vectors_self.append(1)\n",
        "        else:\n",
        "          bool_vectors_self.append(0)\n",
        "\n",
        "      for eles in shingles_set:\n",
        "        if eles in self.shingled_query:\n",
        "          bool_vectors_query.append(1)\n",
        "        else:\n",
        "          bool_vectors_query.append(0)\n",
        "\n",
        "      return bool_vectors_self, bool_vectors_query\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def shingling(self):\n",
        "      k = 8  # Length of each shingle\n",
        "      all_shingles = set()  # Set to store all unique shingles\n",
        "\n",
        "      # Iterate over each document in the 'Text' column of self.documents\n",
        "      for line in self.documents['Text']:\n",
        "          # Split the line into words and remove punctuation\n",
        "          words_list = line.replace(\",\",\"\").replace(\";\",\"\").replace(\".\",\"\").replace(\":\",\"\").split(\" \")\n",
        "\n",
        "          # Iterate over the words to create shingles of length k\n",
        "          for i in range(len(words_list) - k + 1):\n",
        "              # Extract a shingle of length k as a string\n",
        "              shingle = \" \".join(words_list[i:i+k])\n",
        "              all_shingles.add(shingle)  # Add the shingle to the set of all shingles\n",
        "\n",
        "      self.shingled_query = all_shingles  # Set self.shingled_query to the set containing all unique shingles\n",
        "      self.convert_to_boolean_vectors()\n",
        "      return all_shingles\n",
        "\n",
        "    def minhashing(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def locality_sensity_hashing(self):\n",
        "        # Your locality sensitive hashing implementation here\n",
        "        pass\n",
        "\n",
        "    def run(self):\n",
        "        # Run the entire process\n",
        "        self.shingling()  # Call shingling method using self\n",
        "\n",
        "        print(dot(self.boolean_vectors_query, self.boolean_vectors_self) / (norm(self.boolean_vectors_query) * norm(self.boolean_vectors_self)))\n",
        "        return\n",
        "\n",
        "    def approxNearestNeighbors(self, key, n):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "-37WdYFdmzWK"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_file(\"/content/datatest.txt\")\n",
        "minhash_lsh = InMemoryMinHashLSH(data)\n",
        "minhash_lsh.run()"
      ],
      "metadata": {
        "id": "vP3-kXcmnNx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8905b9f-ee23-4d3f-8d3e-777e6d52ab8b"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2705461249780935\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3sNgM1e1lVph"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}